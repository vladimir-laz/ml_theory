{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6e2899-d46a-448b-9bce-c666cb69518f",
   "metadata": {},
   "source": [
    "Here presented most popular classification metrics with their calculation formulas and may be some comments on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78eb55-ef4e-4c57-af0b-030a12b26b7e",
   "metadata": {},
   "source": [
    "[article with good analytics for Acc, Prec, Rec](https://www.evidentlyai.com/classification-metrics/accuracy-precision-recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9b33c-c319-4fa4-80b2-8aaa4136ad4b",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a558af-fe0b-4e6a-9103-83cdb280319e",
   "metadata": {},
   "source": [
    "In binary classification metrics calculation confusion matrix is often used. So, here it is:\n",
    "\n",
    "<div>\n",
    "<img src=\"https://i.ytimg.com/vi/eQrkcFUWhJI/maxresdefault.jpg\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428947b4-9a26-40ff-b34a-f1a4e03e5b14",
   "metadata": {},
   "source": [
    "- ***TP*** (True positives) - objects of the ***positive*** class, classified ***correctly***\n",
    "- ***FP*** (False positives) - objects of the ***positive*** class, classified ***incorrectly***\n",
    "- ***FN*** (False negative) - objects of the ***negative*** class, classified ***incorrectly***\n",
    "- ***TN*** (True negative) - objects of the ***negative*** class, classified ***correctly***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05204e0f-30b5-4104-9f5a-77d77814bc20",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb472725-7efe-411a-bb2c-192ffd799fb5",
   "metadata": {},
   "source": [
    "Accuracy - number of correctly classified objects devided by number of objects\n",
    "$$Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326025d4-28e4-483c-badf-e05da67c8fbc",
   "metadata": {},
   "source": [
    "## Precision/Recall\n",
    "***Precision*** -  measures how often a machine learning model correctly predicts the positive class (among all positive prediction)\n",
    "\n",
    "***Recall*** - measures how often a machine learning model correctly identifies positive instances (true positives) from all the actual positive samples in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9b949-fcda-4764-90c7-35c6e48ef61b",
   "metadata": {},
   "source": [
    "$$Precision = \\frac{TP}{TP+FP}$$ \n",
    "$$Recall = \\frac{TP}{TP+FN}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ffbf1-a202-4868-9a2c-9dd46c8c6dcc",
   "metadata": {},
   "source": [
    "## F1-score\n",
    "***F1 score*** is the ***harmonic mean of precision and recall***, which means that the F1 score will tell you the ***model’s balanced ability to both capture positive cases (recall) and be accurate with the cases it does capture (precision)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59e648-e977-428f-9c2e-363f70fe937e",
   "metadata": {},
   "source": [
    "$$F1 = 2\\frac{Precision*Recall}{Precision+Recall} = \\frac{2*TP}{2*TP+FN+FP}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca88a0-cd14-4c85-9f05-ee3137be9ef6",
   "metadata": {},
   "source": [
    "## $F_{\\beta}$\n",
    "There are situations, when we need to more pay attention to either Recall or Precision. For example, when it comes to cancer diagnosis it's much more important to catch these, who really has a cancer, because missing a cancer diagnosis could be life-threatening. Thus, we need to maximise recall. There are a bunch of other tasks sensitive to specific metric due to it's domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ddecf7-c7cc-47fd-bdfb-3b0cfc170159",
   "metadata": {},
   "source": [
    "$$F_{\\beta} = (1+\\beta^2)\\frac{Precision*Recall}{\\beta^2Precision+Recall} = \\frac{(1+\\beta^2)*TP}{(1+\\beta^2)*TP+\\beta^2*FN+FP}$$ \n",
    "\n",
    "- $\\beta<0$: precision is more important than recall\n",
    "- $\\beta>0$: recall is more important than precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c8bf7-cf9e-49e7-86c5-2bf0750f2276",
   "metadata": {},
   "source": [
    "## Precision-Recall(PR) Curve\n",
    "A PR curve is simply a graph with Precision values on the y-axis and Recall values on the x-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f610b9a-98da-44fd-bc38-295d9fe00ce8",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"https://www.codecamp.ru/content/images/2021/09/precisionRecall2.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e67a33-94c6-4696-aac1-4b2b6dc76ac4",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "plot of the true positive rate (TPR) against the false positive rate (FPR) at each threshold setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614a379-02a2-4e95-b324-77cf244d6a16",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Roc_curve.svg/1200px-Roc_curve.svg.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba041d61-6196-40ab-ba22-f8920e70d1b4",
   "metadata": {},
   "source": [
    "$$TPR = Recall$$\n",
    "\n",
    "$$FPR = \\frac{FP}{TN+FP}$$\n",
    "***TPR = True positive rate***\n",
    "\n",
    "***FPR = False positive rate***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9162b23-f9c0-468b-bfc3-248b3bdfa05b",
   "metadata": {},
   "source": [
    "## Comparence of metric\n",
    "\n",
    "Important note:\n",
    "- ***Type 1 error*** - False Negative\n",
    "- ***Type 2 error*** - False Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff3960-38e4-4723-9c2f-1f11dc52caf2",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-98ao{border-color:inherit;color:#000C2D;font-weight:bold;text-align:left;vertical-align:bottom}\n",
    ".tg .tg-za14{border-color:inherit;text-align:left;vertical-align:bottom}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    ".tg .tg-dusx{border-color:inherit;color:#000C2D;text-align:left;vertical-align:bottom}\n",
    ".tg .tg-7zrl{text-align:left;vertical-align:bottom}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-98ao\">Metrics</th>\n",
    "    <th class=\"tg-98ao\">Resistence to type 1 errors</th>\n",
    "    <th class=\"tg-za14\">Resistence to type 2 errors</th>\n",
    "    <th class=\"tg-za14\">Resistence to imbalanced classes</th>\n",
    "    <th class=\"tg-0pky\"></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-dusx\">Accuracy</td>\n",
    "    <td class=\"tg-dusx\">No</td>\n",
    "    <td class=\"tg-za14\">No</td>\n",
    "    <td class=\"tg-za14\">No</td>\n",
    "    <td class=\"tg-0pky\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dusx\">Precision</td>\n",
    "    <td class=\"tg-dusx\">No</td>\n",
    "    <td class=\"tg-za14\">Yes</td>\n",
    "    <td class=\"tg-za14\">Yes</td>\n",
    "    <td class=\"tg-0pky\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dusx\">Recall</td>\n",
    "    <td class=\"tg-dusx\">Yes</td>\n",
    "    <td class=\"tg-za14\">No</td>\n",
    "    <td class=\"tg-za14\">Yes</td>\n",
    "    <td class=\"tg-0pky\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dusx\">F1-score</td>\n",
    "    <td class=\"tg-dusx\">Yes</td>\n",
    "    <td class=\"tg-za14\">Yes</td>\n",
    "    <td class=\"tg-za14\">Yes</td>\n",
    "    <td class=\"tg-0pky\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-7zrl\">F-beta score</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-0lax\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-7zrl\">PR-AUC</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-0lax\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-7zrl\">ROC-AUC</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-7zrl\">Yes</td>\n",
    "    <td class=\"tg-0lax\"></td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195dcb7b-7397-492b-9723-232ba010bdf1",
   "metadata": {},
   "source": [
    "# Multy-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66e3d8-c5cb-443c-8e46-5e25b269555e",
   "metadata": {},
   "source": [
    "There are two main approaches to multy-class classification:\n",
    "\n",
    "1. ***One-vs-One***: training of K (K − 1) / 2 binary classifiers; each receives the samples of a pair of classes from the original training set, and must learn to distinguish these two classes. At prediction time, a voting scheme is applied: all K (K − 1) / 2 classifiers are applied to an unseen sample and the class that got the highest number of \"+1\" predictions gets predicted by the combined classifier\n",
    "2. ***One-vs-Rest***: training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives. Then one chooses the highest score of all models:\n",
    "$$\\hat{y} = argmax_{k\\in [1, ..., K]}f_k(x)$$, where K is a number of classifiers, $f_k(x)$ - the score of a k-th classifier on an object x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905f306-9cfa-46bf-b7a7-e7769a34ff3a",
   "metadata": {},
   "source": [
    "Most metrics from binary classification can be used for multyclass problem. It can be calculated per every class separately and then be averaged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
