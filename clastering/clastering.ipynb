{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a835f8a-0143-4e73-bb4a-8ead068ad016",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76f729-036e-49b3-9c23-913a34158607",
   "metadata": {},
   "source": [
    "## Silhouette Score\n",
    "\n",
    "Silhouette Score is the mean Silhouette Coefficient for all clusters, which is calculated using the mean intra-cluster distance and the mean nearest-cluster distance. This score is between -1 and 1, where the higher the score the more well-defined and distinct your clusters are\n",
    "\n",
    "***a***: mean distance between the observation and all other data points in the ***same cluster***. This distance can also be called as ***mean intra-cluster distance***\n",
    "\n",
    "***b***: mean distance between the observation and all other data points of the next ***nearest cluster***. This distance can also be called as ***mean nearest-cluster distance***\n",
    "$$S = \\frac{b-a}{max(a, b)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d544c9-a2e4-47e8-b8fd-cb8e77da3b4c",
   "metadata": {},
   "source": [
    "## Calinski-Harabaz Index\n",
    "Calinski-Harabaz Index is calculated using the between-cluster dispersion and within-cluster dispersion in order to measure the distinctiveness between groups. Like the Silhouette Score, the higher the score the more well-defined the clusters are. This score has no bound, meaning that there is no ‘acceptable’ or ‘good’ value\n",
    "\n",
    "1. Calculate inter-cluster dispersion: BGSS(between group sum of squares)\n",
    "$$BGSS = \\sum_{k=1}^K{n_k * ||C_k-C||^2}$$\n",
    "- $𝑛_𝑘$ : the number of observations in cluster 𝑘\n",
    "- $𝐶_𝑘$ : the centroid of cluster 𝑘\n",
    "- 𝐶 : the centroid of the dataset (barycenter)\n",
    "- 𝐾 : the number of clusters\n",
    "\n",
    "2. Calculate intra-cluster dispersion: WGSS(within group sum of squares).\n",
    "$$WGSS_k = \\sum_{k=1}^{n_k}{||X_{ik}-C_k||^2}$$\n",
    "- $𝑛_𝑘$ : the number of observations in cluster 𝑘\n",
    "- $𝑋_{𝑖𝑘}$ : the 𝑖-th observation of cluster 𝑘\n",
    "- $𝐶_𝑘$ : the centroid of cluster 𝑘\n",
    "\n",
    "Then sum all individual within group sums of squares: \n",
    "$$WGSS = \\sum_{k=1}^{K}{WGSS_k}$$\n",
    "\n",
    "3. Calculate Calinski-Harabasz Index\n",
    "$$𝐶𝐻 = \\frac{\\frac{BGSS}{K-1}}{\\frac{WGSS}{N-K}} = \\frac{BGSS}{WGSS}*\\frac{N-K}{K-1}$$\n",
    "- 𝐵𝐺𝑆𝑆 : between-group sum of squares (between-group dispersion)\n",
    "- 𝑊𝐺𝑆𝑆 : within-group sum of squares (within-group dispersion)\n",
    "- 𝑁 : total number of observations\n",
    "- 𝐾 : total number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7807f69-cf95-482e-841c-2f456c46af57",
   "metadata": {},
   "source": [
    "## Davies-Bouldin Index\n",
    "Davies-Bouldin Index is the average similarity of each cluster with its most similar cluster. Unlike the previous two metrics, this score measures the similarity of your clusters, meaning that the lower the score the better separation there is between your clusters?\n",
    "\n",
    "1. Calculate intra-cluster dispersion:\n",
    "$$S_i = \\Bigg\\{\\frac{1}{n_i} \\sum_{j=1}^{T_i} |X_j – C_i|^q \\Bigg\\}^\\frac{1}{q}$$\n",
    "- 𝑖 : particular identified cluster\n",
    "- n_𝑖 : number of vectors (observations) in cluster 𝑖\n",
    "- 𝑋_𝑗 : 𝑗-th vector (observation) in cluster 𝑖\n",
    "- C_𝑖 : centroid of cluster 𝑖\n",
    "- q: hyperparameter. Usually the value 𝑞 is set to 2\n",
    "\n",
    "2. Calculate separation measure:\n",
    "$$M_{ij} = \\Bigg\\{\\sum_{k=1}^{N} |a_{ki} – a_{kj}|^p \\Bigg\\}^\\frac{1}{p} = ||A_i – A_j||_p$$\n",
    "- 𝑎_{𝑘𝑖} : 𝑘-th component of 𝑛-dimensional centroid 𝐴𝑖\n",
    "- 𝑎_{𝑘𝑗} : 𝑘-th component of 𝑛-dimensional centroid 𝐴𝑗\n",
    "- 𝑁 : total number of clusters\n",
    "- p: another hyperparameter. Usually the value p is set to 2\n",
    "\n",
    "3. Calculate similarity between clusters:\n",
    "$$R_{ij} = \\frac{S_i + S_j}{M_{ij}}$$\n",
    "- 𝑆_𝑖 : intra-cluster dispersion of cluster 𝑖\n",
    "- 𝑆_𝑗 : intra-cluster dispersion of cluster 𝑗\n",
    "- 𝑀_{𝑖𝑗} : distance between centroids of clusters 𝑖 and  𝑗\n",
    "\n",
    "4. Find most similar cluster for each cluster 𝑖:\n",
    "$$R_i \\equiv max(R_{ij}), i\\neq j$$\n",
    "5. Calculate Davies-Bouldin Index:\n",
    "$$\\bar{R} = \\frac{1}{N}\\sum_{i=1}^{N}R_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1952bc2-ff9f-4c0f-8ec5-2c295a0a41d8",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe611ab-c39b-434a-8fdc-bb43b52a24cc",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a02e8-0128-42ef-9340-329a6f42028e",
   "metadata": {},
   "source": [
    "1. Choosing the number of clusters\n",
    "2. Initializing centroids\n",
    "3. Assign data points to the nearest cluster\n",
    "4. Re-initialize centroids\n",
    "5. Repeat steps 3 and 4\n",
    "<div>\n",
    "<img src=\"https://ben-tanen.com/assets/img/posts/kmeans-cluster.gif\" width=\"500\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b071dcce-f7ca-4a2b-9dd5-a2ed8ee5862f",
   "metadata": {},
   "source": [
    "## DBSCAN(Density-Based Spatial Clustering of Applications with Noise)\n",
    "There are 2 major hyperparameters to choose when applying DBSCAN:\n",
    "\n",
    "- $\\varepsilon$ – the maximum distance between 2 points for them to be considered neighbors of one another (e.g.: 0.01, 0.5, 2 etc.)\n",
    "- $N$ – the minimum number of neighbors a point needs to have to be considered a core point (e.g.: 3, 5, 10 etc.). This includes the starting point\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "1. We determine which points are core points based on how many neighbors they have. If this number is greater than min_samples, we found a core point.\n",
    "\n",
    "2. Going through the list of core points and spreading the current cluster to other close points. For each new point, if it is a core point, we will use it to propagate the cluster. If not, we mark it as a non-core point.\n",
    "\n",
    "3. All points that have not been assigned to a cluster are marked as outliers.\n",
    "<div>\n",
    "<img src=\"https://i2.wp.com/miro.medium.com/1*WBRWZwSeIw-V4Hw9-_0xrQ.gif\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aac7f0-d905-4590-86f8-df331104c84d",
   "metadata": {},
   "source": [
    "## Gaussian mixture model\n",
    "\n",
    "1. Initialize K Gaussian Distributions (for example posed above, k=2)\n",
    "2. Soft-cluster data (called “expectation” step)\n",
    "3. Re-estimate the Gaussians (called “maximization” step)\n",
    "4. Evaluate the log-likelihood to check for convergence. Repeat from Step #2 until converged.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://media.tenor.com/i1rNMdaKd7MAAAAC/gaussian-mixture-models-em-method-math.gif\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387716ba-842f-4ac1-8e9b-08c9176823f6",
   "metadata": {},
   "source": [
    "## Agglomerating clustering\n",
    "\n",
    "1. Make each data point as a single-point cluster\n",
    "2. Take the two closest distance clusters by single linkage method and make them one clusters. Before using single linkage method on each clusters we must know the distance between clusters\n",
    "3. Repeat step 2\n",
    "\n",
    "<div>\n",
    "<img src=\"https://i2.wp.com/miro.medium.com/1*DyWD0Os_7_pUttb3NVPWYg.gif\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed3d3f5-f2b1-4749-b3b9-4c7a7e00f397",
   "metadata": {},
   "source": [
    "## Comparence of algorithms\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1346/format:webp/1*onJwlGtdSW3mJmmuB2bCdw.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23027c4b-e347-455d-ba37-83960ea8baa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
